{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/rBr+4gisgxSNqN++hpXW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qhfks27/PyTorch/blob/master/RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rUz7Dg7j1L6",
        "colab_type": "text"
      },
      "source": [
        "# RNN\n",
        "\n",
        "RNN : 데이터가 순서대로 나열된 순차적 데이터(sequential data) 혹은 시계열 데이터(time series data)의 정보를 받아 전체 내용을 학습하는 신경망    \n",
        "## 영화 리뷰 감정 분석 (텍스트 감정 분석)\n",
        "   \n",
        "\n",
        "- IMDB : 인터넷 영화 데이터 베이스. 텍스트 형태의 데이터셋   \n",
        "\n",
        "영화 리뷰 텍스트를 RNN에 입력해 영화평 전체 내용을 압축하고 이 압축된 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 만드는 것이 목표이다. \n",
        "\n",
        "긍정적인 영화 리뷰는 2, 부정적인 영화는 1로 레이블링."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2GFaQAWdszt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets       #자연어 데이터셋을 다루므로 토치비전이 아닌 토치텍스트 사용\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtXURpr5dtsv",
        "colab_type": "code",
        "outputId": "d5810e19-a7de-46bf-92cf-b253b36fefe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 20\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", DEVICE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d9Ez9tEiLjl",
        "colab_type": "code",
        "outputId": "544b05fd-6a12-4171-a99a-640e281efdbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)    \n",
        "LABEL = data.Field(sequential=False, batch_first=True)\n",
        "#sequential 파라미터를 이용해 테이터셋이 순차적인 데이터임을 명시\n",
        "#batch_first 파라미터로 신경망에 입력되는 텐서의 첫번째 차원값이 batch_size가 되도록 정함.             \n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n",
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 로딩중...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF-iTKsaiNyB",
        "colab_type": "code",
        "outputId": "63119d40-c0de-4d49-f357-5911248cca1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#IMDB 데이터셋에선 따로 검증셋이 존재하지않아 학습 진행도 확인을 위한 검증셋이 부족해 데이터셋을 쪼개어 사용.\n",
        "trainset, valset = trainset.split(split_ratio=0.8)   \n",
        "#trainset, valset, testset에서 반복할 때마다 배치를 생성해주는 반복자 형성.\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "#사전 속 단어들의 개수와 레이블의 수를 정해준느 변수를 만듦.\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2\n",
        "\n",
        "\n",
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8zlsEmerIb-",
        "colab_type": "text"
      },
      "source": [
        "##LSTM과 GRU\n",
        "-LSTM(Long Short-Term Memory) : 은닉층의 메모리 셀에 입력 게이트, 삭제 게이트, 출력 게이트를 추가하여 불필요한 기억을 지우고 기억해야할 것들을 정하는 RNN   \n",
        "-GRU(Gated Recurrent Unit) : 업데이트 게이트와 리셋 게이트 두가지 게이트만 존재. LSTM보다 학습 속도가 빠르다고 알려져있지만 GRU와 LSTM은 비슷한 성능을 보인다고 알려져있음. GRU는 학습 도중 기울기가 폭발적으로 커지거나 작아지는 현상을 막기위해 개발한 형태."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G15VZy96iV8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(LSTM, self).__init__()\n",
        "        print(\"Building LSTM model...\")\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)      #총 단어의 개수, 임베딩된 단어 텐서가 지니는 텐서값\n",
        "        self.hidden_dim = hidden_dim                       #은닉벡터의 차원값 정의\n",
        "        self.dropout = nn.Dropout(dropout_p)               #드롭아웃 설정\n",
        "        self.lstm = nn.LSTM(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)                                  #임베딩을 통해 영화평들을 벡터의 배열, 시계열 데이터로 변환\n",
        "        h_0 = self._init_state(batch_size=x.size(0))       #첫번째 은닉벡터 정의\n",
        "        c_0 = self._init_state(batch_size=x.size(0))       #cell state 정의\n",
        "        x, _ = self.lstm(x, (h_0, c_0))  # [i, b, h]\n",
        "        h_t = x[:,-1,:]\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data             #가중치 텐서 추출\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()   #첫번째 은닉벡터를 모든 특성값이 0인 벡터가 되도록 설정"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBcqiDfIq2Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        print(\"Building Basic GRU model...\")\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        h_0 = self._init_state(batch_size=x.size(0))\n",
        "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "        h_t = x[:,-1,:]\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGdO80tniWqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):   #반복마다 배치 데이터 반환\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "        optimizer.zero_grad()  #기울기 0으로 초기화\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fmEkM6mieIq",
        "colab_type": "code",
        "outputId": "8690f39a-f29c-4eb2-e682-d7a064866449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = LSTM(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building LSTM model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0jNcT3XijVl",
        "colab_type": "code",
        "outputId": "f6128cf4-7ed9-477a-94b1-68549947e1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
        "    \n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[이폭: 1] 검증 오차: 0.69 | 검증 정확도:49.80\n",
            "[이폭: 2] 검증 오차: 0.69 | 검증 정확도:50.24\n",
            "[이폭: 3] 검증 오차: 0.70 | 검증 정확도:49.64\n",
            "[이폭: 4] 검증 오차: 0.70 | 검증 정확도:49.56\n",
            "[이폭: 5] 검증 오차: 0.72 | 검증 정확도:51.02\n",
            "[이폭: 6] 검증 오차: 0.72 | 검증 정확도:50.36\n",
            "[이폭: 7] 검증 오차: 0.74 | 검증 정확도:53.18\n",
            "[이폭: 8] 검증 오차: 0.72 | 검증 정확도:51.44\n",
            "[이폭: 9] 검증 오차: 0.73 | 검증 정확도:51.48\n",
            "[이폭: 10] 검증 오차: 0.75 | 검증 정확도:51.96\n",
            "[이폭: 11] 검증 오차: 0.74 | 검증 정확도:53.18\n",
            "[이폭: 12] 검증 오차: 0.73 | 검증 정확도:56.92\n",
            "[이폭: 13] 검증 오차: 0.58 | 검증 정확도:73.62\n",
            "[이폭: 14] 검증 오차: 0.71 | 검증 정확도:50.54\n",
            "[이폭: 15] 검증 오차: 0.71 | 검증 정확도:52.98\n",
            "[이폭: 16] 검증 오차: 0.70 | 검증 정확도:58.24\n",
            "[이폭: 17] 검증 오차: 0.58 | 검증 정확도:73.62\n",
            "[이폭: 18] 검증 오차: 0.50 | 검증 정확도:78.16\n",
            "[이폭: 19] 검증 오차: 0.43 | 검증 정확도:83.28\n",
            "[이폭: 20] 검증 오차: 0.45 | 검증 정확도:84.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7hWQ7rHilyT",
        "colab_type": "code",
        "outputId": "d3c66a6f-5396-4aad-8995-1f931028e460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 오차:  0.49 | 테스트 정확도: 80.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x16VAqVXp4jZ",
        "colab_type": "code",
        "outputId": "3a0adafb-11e9-4b8c-b723-165fde109803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (embed): Embedding(46159, 128)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (lstm): LSTM(128, 256, batch_first=True)\n",
            "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0d4Hwh9zjFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE8hsiHuzk3_",
        "colab_type": "code",
        "outputId": "2156d68e-cf39-4a9f-d56b-de58b9ea1408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count = count_parameters(model)\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6304130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvUOol-E7j1H",
        "colab_type": "text"
      },
      "source": [
        "##Seq2Seq 기계번역\n",
        "영어 알파벳 문자열(\"hello\")를 스페인어 알파벳 문자열(\"hola\")로 번역하는 비니 Seq2Seq 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l95DwZVl7oof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giEejxun7tLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c7a436b-02a3-4337-bf0a-45196bf22807"
      },
      "source": [
        "vocab_size = 256  # 총 아스키 코드 개수\n",
        "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
        "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
        "print(\"hello -> \", x_)\n",
        "print(\"hola  -> \", y_)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello ->  [104, 101, 108, 108, 111]\n",
            "hola  ->  [104, 111, 108, 97]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxSn9hPY709-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.LongTensor(x_)\n",
        "y = torch.LongTensor(y_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApCUwzU_74dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.project = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 인코더에 들어갈 입력\n",
        "        initial_state = self._init_state()\n",
        "        embedding = self.embedding(inputs).unsqueeze(1)\n",
        "        # embedding = [seq_len, batch_size, embedding_size]\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
        "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
        "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
        "\n",
        "        # 디코더에 들어갈 입력\n",
        "        decoder_state = encoder_state\n",
        "        decoder_input = torch.LongTensor([0])\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        outputs = []\n",
        "        \n",
        "        for i in range(targets.size()[0]):\n",
        "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
        "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
        "            projection = self.project(decoder_output)\n",
        "            outputs.append(projection)\n",
        "            \n",
        "            #티처 포싱(Teacher Forcing) 사용\n",
        "            decoder_input = torch.LongTensor([targets[i]])\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze()\n",
        "        return outputs\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQph0GL78FFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq2seq = Seq2Seq(vocab_size, 16)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSs5RXN88Hd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "da981dd5-8998-47b3-aef4-ba82cffcfae2"
      },
      "source": [
        "log = []\n",
        "for i in range(1000):\n",
        "    prediction = seq2seq(x, y)\n",
        "    loss = criterion(prediction, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = loss.data\n",
        "    log.append(loss_val)\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
        "        _, top1 = prediction.data.topk(1, 1)\n",
        "        print([chr(c) for c in top1.squeeze().numpy().tolist()])\n",
        "\n",
        "\n",
        "plt.plot(log)\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 반복:0 오차: 5.588308334350586\n",
            "['Ý', 'à', 'à', '¹']\n",
            "\n",
            " 반복:100 오차: 2.3219153881073\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:200 오차: 0.571672797203064\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:300 오차: 0.24141940474510193\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:400 오차: 0.14347510039806366\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:500 오차: 0.09880569577217102\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:600 오차: 0.07352884858846664\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:700 오차: 0.05742623656988144\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:800 오차: 0.046365875750780106\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:900 오차: 0.038359031081199646\n",
            "['h', 'o', 'l', 'a']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8Jupz91FEsrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}